{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31391838-4022-4d2f-9e0b-e9448ae9d3db",
   "metadata": {},
   "source": [
    "# 1-Import"
   ]
  },
  {
   "cell_type": "raw",
   "id": "66396b91-f2ce-45d5-a6c5-bc914686ffdf",
   "metadata": {},
   "source": [
    "%pip install plot_keras_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d6e894f-920e-4508-92e5-a2beab7e3816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\John\\Desktop\\venv\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from time import time\n",
    "import math\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize, LabelEncoder\n",
    "from sklearn.utils import class_weight, shuffle\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, GlobalAveragePooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from plot_keras_history import show_history, plot_history\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "# For normalization\n",
    "import cv2\n",
    "from skimage.exposure import match_histograms\n",
    "\n",
    "os.environ[\"TF_KERAS\"]='0'\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd224e89-f8dd-4577-8788-e0ed35f4fc09",
   "metadata": {},
   "source": [
    "# 2-Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d04f845-e0a7-4d81-8ea8-cb28b7f71bfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel(r\"C:\\Users\\John\\Desktop\\camcontrol\\data\\train.xlsx\")\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08353cee-f7bb-4427-b461-8ca74a294a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Label'].fillna('other', inplace=True)\n",
    "df.loc[df['Label']=='nc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec5e4d2-66ab-4d6f-8e33-80fa80ed952e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Wall time 18s\n",
    "# Visualisation de quelques images en vrac\n",
    "plt.figure(figsize=(10, 10)) \n",
    "\n",
    "for i, row in df.head(9).iterrows():\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(plt.imread(row['Image_Path']))\n",
    "    plt.title(f\"Label: {row['Label']}\")\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62eb7b35-19e0-41ac-8285-b2b6a5fdaad8",
   "metadata": {},
   "source": [
    "# 3-Model Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f644ae-c42f-481c-8136-73dd5fecbff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter definition\n",
    "\n",
    "# Number of classes\n",
    "nb_lab = len(df['Label'].unique())\n",
    "\n",
    "# Class list\n",
    "le = LabelEncoder()\n",
    "le.fit_transform(df['Label'])\n",
    "list_lab = le.classes_\n",
    "\n",
    "epochs_dic = {1:1, 2:15, 3:30}\n",
    "batch_size_dic = {1:16, 2:32, 3:64}\n",
    "optimizer_dic = {1:'Adam', 2:'rmsprop'}\n",
    "normalization_dic = {1:None}\n",
    "label_dic = {1:list_lab}\n",
    "preprocessing_input_dic = {1:preprocess_input}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9bc1f2a-cf19-401e-9b9b-934e57d02fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation function for train-val\n",
    "def data_flow_fct(data, datagen, data_type=None, batch_size=None) :\n",
    "\n",
    "    data_flow = datagen.flow_from_dataframe(data,\n",
    "                                            #directory=dir_, # Pas besoin\n",
    "                                            x_col='Image_Path',  # Utilisez 'image_path' comme colonne des chemins d'images\n",
    "                                            y_col='Label',#_name',\n",
    "                                            weight_col=None,\n",
    "                                            target_size=(224, 224),\n",
    "                                            classes=None,\n",
    "                                            class_mode='categorical',\n",
    "                                            batch_size=batch_size,\n",
    "                                            shuffle=False,\n",
    "                                            seed=42,\n",
    "                                            subset=data_type)\n",
    "    return data_flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ee29c6-c328-437e-a428-1e8a800401a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation function\n",
    "def datagen_trainer(preprocessing_input):\n",
    "    datagen_train = ImageDataGenerator(\n",
    "    #    featurewise_center=True,\n",
    "    #    featurewise_std_normalization=True,\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        validation_split=0.25,# détermine le ration training/validation\n",
    "        preprocessing_function=preprocessing_input)\n",
    "    return datagen_train\n",
    "\n",
    "def datagen_tester(preprocessing_input):\n",
    "    datagen_test = ImageDataGenerator(\n",
    "        validation_split=0,\n",
    "        preprocessing_function=preprocess_input)\n",
    "    return datagen_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299e8f74-ef46-4417-aad1-28cd9cd46d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model creation function\n",
    "def create_model_fct(nb_lab) :\n",
    "    #weights_path = \"/kaggle/input/vgg16-weights/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\" # ATTENTION : activer hors connexion\n",
    "    weights_path = 'imagenet'\n",
    "    # Charger le modèle VGG16 pré-entraîné\n",
    "    model0 = VGG16(include_top=False, weights=weights_path, input_shape=(224, 224, 3)) \n",
    "    \n",
    "    # Layer non entraînables = on garde les poids du modèle pré-entraîné\n",
    "    for layer in model0.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Récupérer la sortie de ce réseau\n",
    "    x = model0.output\n",
    "    # Compléter le modèle\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(224, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    predictions = Dense(nb_lab, activation='softmax')(x)\n",
    "\n",
    "    # Définir le nouveau modèle\n",
    "    model = Model(inputs=model0.input, outputs=predictions)\n",
    "       \n",
    "    # compilation du modèle \n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer_dic[1], metrics=[\"accuracy\"])\n",
    "\n",
    "    print(model.summary())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2777141-1a46-449d-bfca-709b31a9fa94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step flow definition\n",
    "def define_flow(preprocessing_flow, batch_size_flow):\n",
    "    # Data augmentation for train-val\n",
    "    train_flow = data_flow_fct(data, datagen_trainer(preprocessing_flow), data_type='training',batch_size=batch_size_flow)\n",
    "    val_flow = data_flow_fct(data, datagen_trainer(preprocessing_flow), data_type='validation',batch_size=batch_size_flow)\n",
    "    test_flow = data_flow_fct(data, datagen_tester(preprocessing_flow), data_type=None, batch_size=1)\n",
    "    return train_flow, val_flow, test_flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd5e640-d647-46c1-a26e-c972d6500b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step model creation and training\n",
    "def model_creation_training(train_flow, val_flow,epochs_entry):\n",
    "    # 4min35 for epochs = 1 and batch_size = 32\n",
    "    # Model creation and training\n",
    "    with tf.device('/gpu:0'):\n",
    "\n",
    "        # Model creation\n",
    "        print('1/3-Model creation')\n",
    "        model = create_model_fct(nb_lab)\n",
    "\n",
    "        # Call back creation\n",
    "        print('2/3-Callbacks')\n",
    "        model_save_path = r\"C:\\Users\\John\\Desktop\\camcontrol\\models\\trained_model.h5\"\n",
    "        checkpoint = ModelCheckpoint(model_save_path, monitor='val_accuracy', verbose=1, mode='max', save_best_only=True)\n",
    "        es = EarlyStopping(monitor='val_accuracy', mode='max', verbose=1, patience=10)\n",
    "        callbacks_list = [checkpoint, es]\n",
    "\n",
    "        # Training\n",
    "        print('3/3-Training')\n",
    "        history = model.fit(train_flow, epochs=epochs_entry, \n",
    "                            steps_per_epoch=len(train_flow),\n",
    "                            callbacks=callbacks_list, \n",
    "                            validation_data=val_flow,\n",
    "                            validation_steps=len(val_flow),\n",
    "                            verbose=1)\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6c2126-bc4a-4d52-aeee-a77fba155f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step performance train_val\n",
    "def performance_train_val(history, model, val_flow, batch_size_entry):\n",
    "    # Performances\n",
    "    print('1/6-val accuracy/epochs')\n",
    "    show_history(history)\n",
    "    plot_history(history, path=r\"C:\\Users\\John\\Desktop\\camcontrol\\reports\\history_train_val.png\")\n",
    "    plt.close()\n",
    "\n",
    "    print('2/6-predicting y_pred')\n",
    "    #1min 28 for batch_size = 32\n",
    "    y_pred = model.predict(val_flow, steps=len(val_flow), batch_size=batch_size_entry)\n",
    "\n",
    "    print('3/6-getting y_val')\n",
    "    nombre_total_val = len(val_flow) * batch_size_entry\n",
    "\n",
    "    # Initialisation d'un tableau pour stocker les étiquettes réelles\n",
    "    y_val = np.zeros((nombre_total_val, nb_lab))  \n",
    "\n",
    "    # Itérer sur le générateur pour extraire les étiquettes réelles\n",
    "    for i in range(len(val_flow)):\n",
    "        _, batch_y_val = val_flow[i]  # Supposons que le générateur génère des paires (X_val, y_val)\n",
    "        start_index = i * batch_size_dic[1]\n",
    "        end_index = start_index + len(batch_y_val)\n",
    "        y_val[start_index:end_index] = batch_y_val\n",
    "\n",
    "    print('4/6-building the basic confusion matrix')\n",
    "    # Obtenez les indices des classes prédites et réelles pour les échantillons disponibles\n",
    "    y_val_indices = y_val.argmax(axis=1)[0:len(y_pred)]\n",
    "    y_pred_indices = y_pred.argmax(axis=1)\n",
    "\n",
    "    # Générer la matrice de confusion\n",
    "    cm = confusion_matrix(y_val_indices, y_pred_indices)\n",
    "\n",
    "    # Afficher la matrice de confusion\n",
    "    print(cm)\n",
    "\n",
    "    # Afficher le rapport de classification\n",
    "    print(\"\\n5/6-building the classification report\")\n",
    "    print(classification_report(y_val.argmax(axis=1)[0:len(y_pred)], y_pred.argmax(axis=1)))\n",
    "\n",
    "    print('6/6-building the sns confusion matrix')\n",
    "    # Finding the matching categorical labels for the numerical labels\n",
    "    list_num_labels = sorted([x for x in set(y_val_indices)|set(y_pred_indices)])\n",
    "    list_cat_labels = le.inverse_transform(list_num_labels)\n",
    "\n",
    "    # Proceeding with sns\n",
    "    df_cm = pd.DataFrame(cm, index=list_cat_labels, columns=list_cat_labels)\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    ax = sns.heatmap(df_cm, annot=True, cmap=\"Blues\")\n",
    "\n",
    "    # Ajouter des étiquettes aux axes\n",
    "    ax.set_xlabel(\"Prediction\")\n",
    "    ax.set_ylabel(\"True\")\n",
    "    ax.set_title(\"confusion matrix train_val\")\n",
    "    # Sauvegardez l'image dans un fichier\n",
    "    plt.savefig(r'C:\\Users\\John\\Desktop\\camcontrol\\reports\\confusion_matrix_train_val.png')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9a95ee-52c4-405e-85ec-28d293c87224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step performance test\n",
    "# Performance\n",
    "def performance_test(model, test_flow):\n",
    "    print('getting y_pred')\n",
    "    # Testing on whole dataset\n",
    "    #y_pred = model.predict(images_np)\n",
    "    y_pred = model.predict(test_flow, steps=len(test_flow), batch_size=1)\n",
    "\n",
    "    print('4/6-building the basic confusion matrix')\n",
    "    # get y_val and y_pred\n",
    "    y_pred_indices = y_pred.argmax(axis=1)\n",
    "    y_pred_cat = le.inverse_transform(y_pred_indices)\n",
    "\n",
    "    y_val_cat = data['Label'][0:len(y_pred_cat)]\n",
    "\n",
    "    # Générer la matrice de confusion\n",
    "    cm = confusion_matrix(y_val_cat, y_pred_cat)\n",
    "\n",
    "    # Afficher la matrice de confusion\n",
    "    print(cm)\n",
    "\n",
    "    # Afficher le rapport de classification\n",
    "    print(\"\\n5/6-building the classification report\")\n",
    "    print(classification_report(y_val_cat, y_pred_cat))\n",
    "\n",
    "    print('6/6-building the sns confusion matrix')\n",
    "\n",
    "    # Proceding with sns\n",
    "    df_cm = pd.DataFrame(cm, index=label_dic[1], columns=label_dic[1])\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    ax = sns.heatmap(df_cm, annot=True, cmap=\"Blues\")\n",
    "\n",
    "    # Ajouter des étiquettes aux axes\n",
    "    ax.set_xlabel(\"Prediction\")\n",
    "    ax.set_ylabel(\"True\")\n",
    "    ax.set_title(\"confusion matrix test\")    \n",
    "    # Sauvegardez l'image dans un fichier\n",
    "    plt.savefig(r'C:\\Users\\John\\Desktop\\camcontrol\\reports\\confusion_matrix_test.png')\n",
    "\n",
    "    plt.show()\n",
    "    return y_val_cat, y_pred_cat, y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0fd5e1-6f2a-4e90-8ff5-5a992b8af5da",
   "metadata": {},
   "source": [
    "# 4-Training/Validation/Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c00269d-b0b3-40a1-b8b4-26b83c78d289",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# 2min 30s\n",
    "print('Step 1 : data collection')\n",
    "data = df\n",
    "\n",
    "results = pd.DataFrame(columns=['optimizer','method','test_accuracy', 'processing_time'])\n",
    "chrono = time()\n",
    "for i in range(2,3):#rmsprop\n",
    "    for j in range(1,2):#preprocess_input\n",
    "\n",
    "        epochs_entry = epochs_dic[2]#15\n",
    "        batch_size_entry = batch_size_dic[1]#16\n",
    "        optimizer_entry = optimizer_dic[i]\n",
    "        preprocessing_entry = preprocessing_input_dic[j]\n",
    "\n",
    "        print('Step 2 : flow definition')\n",
    "        train_flow, val_flow, test_flow = define_flow(preprocessing_entry, batch_size_entry)\n",
    "\n",
    "        print('Step 3 : model creation and training')\n",
    "        model_0, history_0 = model_creation_training(train_flow, val_flow, epochs_entry)\n",
    "\n",
    "        print('Step 4 : performance train_val')\n",
    "        # Step performance train_val\n",
    "        performance_train_val(history_0, model_0, val_flow, batch_size_entry)\n",
    "\n",
    "        #print('Step (en l'absence de flow) : préparation des images')\n",
    "        # Step préparation des images (les images ne sont pas traitées !!)\n",
    "        #images_np = image_prep_fct(data)\n",
    "        #print(images_np.shape)\n",
    "\n",
    "        print('Step 5 : performance test')\n",
    "        y_val_cat, y_pred_cat, y_pred = performance_test(model_0, test_flow)\n",
    "\n",
    "        print('Step 6 : recording performance')\n",
    "        chrono = time() - chrono\n",
    "        results.loc[len(results)] = [optimizer_entry, preprocessing_entry.__name__, accuracy_score(y_val_cat, y_pred_cat), chrono]\n",
    "        chrono = time()\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24ca047-6ef2-4896-8a2e-8360d1f5cd29",
   "metadata": {},
   "source": [
    "# 5-Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ea1b33-0b22-4149-a9ea-e88959ca636d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['Pred'] = le.inverse_transform(np.argmax(y_pred, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7aa4894-88ca-4e14-8337-1f301a952745",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "import openpyxl\n",
    "from openpyxl.drawing.image import Image\n",
    "import PIL\n",
    "import cv2\n",
    "from datetime import datetime, timedelta\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694e0d6e-0f64-41b3-8b87-017102ee2795",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(r\"C:\\Users\\John\\Desktop\\camcontrol\\data\\tested.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea68c2a1-2e72-4db0-a758-176db8572aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définissons l'emplacement des différents dossiers et fichiers\n",
    "# Le dossier où sont stockées les images d'entraînement\n",
    "dir_train = r\"C:\\Users\\John\\Desktop\\camcontrol\\data\\train\"\n",
    "# Le tableau des données inférées\n",
    "dataset = r\"C:\\Users\\John\\Desktop\\camcontrol\\data\\tested.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4dd648-1145-4052-8a2f-266f709acef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On va rajouter un thumbnail à chaque ligne\n",
    "# 1-Instanciation un objet Openpyxl de tested.xlsx\n",
    "try:\n",
    "    # On essaie d'ouvrir le fichier Excel s'il existe déjà.\n",
    "    file_path = dataset\n",
    "    workbook = openpyxl.load_workbook(file_path)\n",
    "    #print(f\"Fichier Excel existant ouvert : {file_path}\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"fichier non trouvé\")\n",
    "\n",
    "worksheet = workbook.active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35d0cad-5a4d-4126-b6bc-60e0af056d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2-On ajoute les thumbnails dans le document Openpyxl\n",
    "for idc, image_path in tqdm(enumerate(df['Image_Path'])):\n",
    "    # Resize cells ligne idx+2\n",
    "    worksheet.row_dimensions[idc+2].height = 50\n",
    "\n",
    "    # Collage du thumbnail sur la cellule colonne Hde la ligne idx+2\n",
    "    # la première ligne qui contient les en-têtes des colonnes provoquent une exception\n",
    "    try : \n",
    "        img = cv2.imread(df.iloc[idc,0])\n",
    "    except :\n",
    "        continue\n",
    "    img = cv2.resize(img, (50, 50))\n",
    "    \n",
    "    # On sauvegarde l'image.son nom est img suivi de l'indice de la ligne où elle est collée\n",
    "    img = cv2.imwrite(r'C:\\Users\\John\\Desktop\\camcontrol\\data\\interim\\img{idc+2}.png', img)\n",
    "\n",
    "    worksheet.add_image(Image(r'C:\\Users\\John\\Desktop\\camcontrol\\data\\interim\\img{idc+2}.png'), anchor=f'H{idc+2}')#il faut que Image soit un objet Openpyxl et non pas PIL       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525242d3-6bd1-490e-8ad8-347b5ec61a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3-Sauvegarde du document data_set_train.xls avec ses thumbnails prêt à une labellisation manuelle\n",
    "workbook.save(dataset)\n",
    "workbook.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
